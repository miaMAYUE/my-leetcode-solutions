797. 所有可能的路径：

```python
class Solution:
    def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
        ans=[]
        def dfs(i,path):
            if i==len(graph)-1:
                ans.append(path)
            for j in graph[i]:
                dfs(j,path+[j])
        dfs(0,[0])
        return ans
```

# other method 1【记忆化递归】

## 一、核心思路：自顶向下的“反向”路径构建

常规的深度优先搜索（DFS）是从起点 `0` 一步步走向终点。而此处的“记忆化递归”解法采用了一种更函数式的“反向”思考模式。

我们定义一个核心函数 `dfs(node)`，并明确它的唯一目标：

> **`dfs(node)` 函数负责计算并返回从 `node` 节点出发，到达终点 `n-1` 的所有路径的列表。**

理解了这个核心契约，整个逻辑就豁然开朗了：
- 想求从 `0` 到 `n-1` 的所有路径，我只需要调用 `dfs(0)` 即可。
- 在 `dfs(node)` 内部，我不需要关心“我是从哪儿来的”，我只关心“我接下来能去哪儿，以及从那些地方出发能到终点吗？”。
- 具体来说，`dfs(node)` 会遍历其所有邻居 `nxt`，然后向它们分别“索要”结果：`dfs(nxt)`。
- 拿到从邻居 `nxt` 到终点的所有路径后，`dfs(node)` 只需在这些路径的最前面加上自己 `node`，就构成了从 `node` 出发的所有路径。
- 这个递归的最终出口（Base Case）是 `dfs(n-1)`。当递归到终点时，它到自身的路径只有一条，即 `[n-1]`，将此作为结果返回。

路径就这样从终点开始，一层层地“反向”构建，最终汇集到起点。

---

## 二、完整代码

```python
from functools import lru_cache
from typing import List

class Solution:
    def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
        n = len(graph)

        @lru_cache(None)
        def dfs(node):
            # 1. 递归的终止条件 (Base Case)
            if node == n - 1:
                # 返回一个包含单条路径的列表: [[n-1]]
                return [[n - 1]]
            
            # 2. 递归的递推关系
            ans = []
            for nxt in graph[node]:
                # 递归调用，获取从邻居 nxt 到终点的所有路径
                for res_path in dfs(nxt):
                    # 将当前节点拼接到每条子路径的前面
                    ans.append([node] + res_path)
            
            # 3. 返回从 node 出发的所有路径
            return ans
        
        # 程序的入口
        return dfs(0)
```

---

## 三、专题解析 1：`@lru_cache(None)` 的魔力

`@lru_cache(None)` 是 Python `functools` 模块提供的**装饰器（Decorator）**，它是实现**记忆化（Memoization）**的强大工具。

### 它是如何工作的？
你可以把它想象成给 `dfs` 函数外挂了一个“记忆字典”。
- 当 `dfs(node)` **第一次**被调用时（例如 `dfs(3)`），它会正常计算结果，并在返回前将结果存入缓存，例如 `cache[3] = [[3, 7]]`。
- 当 `dfs(node)` **再次**以相同的参数被调用时（例如，另一条路径也到达了节点3，又要执行 `dfs(3)`），它会直接从缓存中读取 `cache[3]` 的结果并返回，完全跳过函数内部的计算过程。

### 为什么在这里有效？
本题的图是一个**有向无环图（DAG）**，不同的路径可能会汇合到同一个节点上（例如 `0->1->3` 和 `0->2->3`）。如果没有记忆化，`dfs(3)` 会被重复计算多次。`@lru_cache` 避免了这种冗余，确保每个节点的“后续路径”只被计算一次。

### `(None)` 参数是什么？
`lru_cache` 的 `maxsize` 参数用于指定缓存的大小。当 `maxsize` 被设为 `None` 时，缓存大小无限制，可以存储所有函数调用的结果。对于本题节点数较少的情况，这是一个简单有效的选择。

---

## 四、专题解析 2：`[node] + res_path` 的路径拼接

这一行代码 `ans.append([node] + res_path)` 是路径构建的核心，它展示了 Python 列表操作的简洁性。

我们用一个具体例子来理解：
假设当前执行到 `dfs(1)`，且 `node` 的值是整数 `1`。它的一个邻居是 `3`。
程序递归调用 `dfs(3)`，并返回了一个从 `3` 到终点的路径列表，比如 `[[3, 7]]`。

现在 `for res_path in dfs(3):` 循环开始执行：
- 循环的第一次（也是唯一一次），`res_path` 的值是列表 `[3, 7]`。
- 我们需要把当前节点 `1` 放在这条路径的最前面。
- 在 Python 中，`+` 运算符可以用于拼接两个列表。但我们不能直接用整数和列表相加（`1 + [3, 7]` 会导致 `TypeError`）。
- 因此，我们先将整数 `node` 包装成一个单元素的列表 `[node]`，也就是 `[1]`。
- 接着执行列表拼接：`[1] + [3, 7]`，得到新的列表 `[1, 3, 7]`。
- 最后，`ans.append([1, 3, 7])` 将这条新构建的、从 `1` 开始的完整路径加入到结果集中。

这个过程本质上是在所有“子路径”的前面加上当前节点，从而构建出更长的路径。

---

## 四、专题解析 3：`Python 中的 for` 为什么函数返回值可以作为for的池子

因为for 循环关心的不是“池子”是怎么来的，而仅仅是这个“池子”本身是不是一个可以一个挨一个取出东西的`可迭代对象 (Iterable)`。

Python 的 for 循环在设计上非常灵活。它的工作原理可以简化为以下“契约”：
`for 变量 in 池子`:
只要你提供给我的“池子”是一个可迭代对象，我就能正常工作。

什么是`可迭代对象 (Iterable)`？
通俗地讲，就是任何能让你一个接一个地从中取出元素的东西。我们日常使用的很多数据类型都是可迭代对象，例如：
- 列表 (List): [1, 2, 3]
- 字符串 (String): "abc"
- 元组 (Tuple): (1, 2, 3)
- 字典 (Dictionary): {'a': 1, 'b': 2} (可以遍历它的键、值或键值对)
- 集合 (Set): {1, 2, 3}
- 等等...

---

## 五、总结

此解法有两个核心思想：
1.  **递归函数的定义**：将 `dfs(node)` 定义为求解“从 `node` 到终点的所有路径”，从而将复杂问题分解为结构相同的子问题。
2.  **记忆化缓存**：利用 `@lru_cache` 避免在有向无环图（DAG）中对汇合节点的重复计算，是动态规划和图论问题中常见的优化手段。

---

## thinking
思考递归相关的问题时，先思考k和k+1的关系（类似数学归纳），先给第k+1次调用一个假设的返回值（根据题目中递归的用意），看看k次会发生什么，不用一开始就从底部开始回推。


# other method 2：广度优先搜索 (BFS) 

## 一、核心思路：广度优先搜索 (BFS) 与路径记录

标准的广度优先搜索（BFS）通常用于在图中寻找**最短路径**，它使用的是一个队列来存储**待访问的节点**。

为了解决我们这个“寻找所有路径”的问题，我们对标准BFS做一个巧妙的改造：

> **队列中存储的不再是单个节点，而是从起点 `0` 出发到达某个节点的完整路径。**

整个算法的流程就像这样：
1.  首先，队列里只有一条路径，就是 `[0]`，代表我们正站在起点。
2.  我们从队列的左侧取出一条路径（第一次是`[0]`），检查它是否到达终点。
3.  如果没到终点，我们就看看这条路径的最后一个节点能去向哪些邻居。
4.  对于每一个邻居，我们都将它追加到当前路径的末尾，形成一条条新的、更长的路径，然后将这些新路径放入队列的末尾（右侧），等待后续探索。
5.  这个过程不断重复，我们探索的路径层层递进（路径长度为1，然后是长度为2，以此类推），直到队列为空，说明所有可能的路径都已被探索完毕。

---

## 二、逐行代码解析

```python
from collections import deque
from typing import List

class Solution:
    def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
        n = len(graph)
        
        # 1. 初始化队列 (queue)
        # deque 是一个双端队列，从左边取出 (popleft) 和从右边加入 (append) 的时间复杂度都是 O(1)，效率很高。
        # q 是一个暂存器，暂时存放没到终点的路径，每条路径到了终点n-1时，只从q左出然后进ans，不再回q。
        # 队列的初始状态是 deque([[0]])。
        # 这是一个包含“列表的列表”，意思是：我们的队列中当前只有一项待办任务，
        # 这个任务就是探索路径 [0]。
        q = deque([[0]])
        
        # 2. 初始化结果列表，用于存放所有成功到达终点的路径
        ans = []

        # 3. 当队列不为空时，持续循环
        while q:
            # 4. 从队列的“头部”（左边）取出一个路径进行处理
            # BFS 的核心是先进先出，所以用 popleft()
            path = q.popleft() # 比如，第一次取出的是 [0]

            # 5. 获取当前路径的最后一个节点，判断是否为终点
            last_node = path[-1]
            if last_node == n - 1:
                # 如果是终点，说明找到了一条完整路径，将其加入结果列表
                ans.append(path)
                # 这条路径已经到头，无需再扩展，直接开始下一次循环
                continue
            
            # 6. 如果不是终点，则扩展当前路径
            # 找到最后一个节点的所有邻居
            for nxt in graph[last_node]:
                # 对于每个邻居 nxt，生成一条新路径
                # new_path = path + [nxt]  (例如 [0] + [1] 得到 [0, 1])
                # 将这条新路径加入到队列的“尾部”（右边）
                q.append(path + [nxt])
                
        # 7. 当队列为空，说明所有路径都已探索完毕，返回结果
        return ans
```

---
## 三、Python 中的 `deque` 双端队列

append(x): 在**右边（队尾）**添加元素 x。
appendleft(x): 在**左边（队头）**添加元素 x。
pop(): 从**右边（队尾）**移除并返回一个元素。
popleft(): 从**左边（队头）**移除并返回一个元素。

list  ：Python 的 list 是用**动态数组（Dynamic Array）**实现的。你可以把它想象成一排实体座位。
deque ：内部是用**双向链表（Doubly Linked List）**实现的（更准确地说是块状双向链表）。它不要求内存是连续的。

| 特征 (Feature) | `collections.deque` | `list` (列表) |
| :--- | :--- | :--- |
| **底层数据结构** | 双向链表 (或其变体) | 动态数组 |
| **两端添加/删除** | **非常快 ($O(1)$)** | **头部慢 ($O(N)$), 尾部快 ($O(1)$)** |
| **中间元素访问** | 慢 ($O(N)$) | **非常快 ($O(1)$)** |
| **主要应用场景** | 队列 (BFS)、栈、滑动窗口、需要频繁操作两端的场景 | 通用数据存储、需要快速按索引访问的场景 |

**总结:**

- 当你需要一个**高效的队列 (FIFO)**，或者需要在数据序列的**两头**频繁地进行添加和删除操作时，请使用 `deque`。
- 当你需要**频繁地通过索引访问**列表中的任意元素（例如 `my_list[i]`），或者主要在列表**末尾**进行操作时，`list` 是更好的选择。

## 四、与“记忆化递归”的对比

* **探索顺序:** BFS 按路径长度逐层探索，总是先发现较短的路径。DFS（递归）则是一条路走到黑，再回头走另一条路。
* **数据结构:** BFS 显式地使用**队列 (Queue)**。DFS 隐式地使用**调用栈 (Call Stack)**。
* **路径构建:** BFS 从起点**向前**构建路径 (`path + [nxt]`)。我们之前讨论的递归解法是从终点**向后**构建路径 (`[node] + res_path`)。

对于这道题，两种方法都是正确且有效的，它们只是代表了两种不同的图遍历思想。BFS 的迭代写法通常更易于理解，且在寻找最短路径的场景下有天然优势。

# other method 3：经典回溯法 (Backtracking) 

## 一、核心思路：回溯法与“状态”的维护

回溯算法的核心在于“**选择、探索、撤销**”的循环。它本质上是一种带有“剪枝”的深度优先搜索（DFS）。

1.  **一个共享的路径 `path`**：与之前的解法不同，这里我们自始至终只维护**一个**列表 `path`，它代表了当前正在探索的路径。

2.  **做出选择 (Choose)**：在当前路径的最后一个节点，我们从它的邻居中选择一个，作为下一步要走的路。

3.  **向前探索 (Explore)**：将选择的邻居节点加入到 `path` 的末尾，然后基于这个**新的路径**，继续递归地向下探索。

4.  **撤销选择 (Unchoose/Backtrack)**：当从更深层的探索返回后（无论是找到了解还是走到了死胡同），我们必须将刚才加入到 `path` 的节点**移除**。这个“撤销”的步骤至关重要，它使得程序能够“回到”上一个状态，去尝试其他的选择。

这个过程就像在走一个迷宫，你走到一个岔路口，选择一条路走下去。如果这条路是死胡同，你就退回到刚才的岔路口，再尝试另一条路。`path` 就好比你一路上撒下的面包屑，记录着你当前的位置。

---

## 二、逐行代码解析

```python
from typing import List

class Solution:
    def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
        n = len(graph)
        # 1. 初始化当前路径和结果列表
        # path 是一个可变列表，全程共享，记录当前探索的路径。初始为 [0]。
        path = [0]
        # ans 用于存储所有找到的完整路径。
        ans = []
        
        def backtracking():
            # 2. 递归的终止条件（找到一个解）
            # 检查当前路径的最后一个节点是否为终点
            if path[-1] == n - 1:
                # 如果是，说明找到了一条完整路径。
                # 必须用 list(path) 或 path[:] 创建一个 path 的副本！
                # 因为 path 之后还会被修改（pop），如果直接 append(path)，
                # ans 里的内容会随着 path 的变化而变化，最后都变成空。
                ans.append(list(path))
                # 注意：这里可以不用 return，因为题目保证终点没有出度，for循环不会执行，函数会自动返回。
                # 写 return 也可以，结构更明显。
                return

            # 3. 遍历所有可能的选择
            # 获取当前路径最后一个节点的所有邻居
            for nxt in graph[path[-1]]:
                # 3.1 做出选择
                path.append(nxt)
                # 3.2 向前探索
                # 基于新路径，继续递归调用
                backtracking()
                # 3.3 撤销选择
                # 当上面的 backtracking() 调用结束后（意味着从 nxt 出发的所有可能都已探索完毕），
                # 将 nxt 从路径中移除，恢复到进入循环前的状态，以便尝试下一个邻居。
                # 这就是“回溯”的核心。
                path.pop()
        
        # 4. 启动回溯
        backtracking()
        return ans
```

---

## 三、回溯法 vs. 记忆化递归

虽然两者都基于深度优先搜索，但它们的实现思路和状态管理方式有显著不同：

* **状态管理**：
    * **回溯法**：通常使用一个**共享、可变**的状态（如此处的 `path` 列表），通过 `append` 和 `pop` 来修改这个状态。它更关注“我当前走到了哪里”。
    * **记忆化递归**：通常是**不可变**的。每次递归调用都基于上一次的结果创建**新的**路径列表 (`[node] + res_path`)。它更关注“从我这里出发，能得到什么结果”。

* **关注点**：
    * **回溯法**：重点在于**过程的模拟**，即“选择-探索-撤销”这个模板。
    * **记忆化递归**：重点在于**子问题的重复性**和**结果的复用**，通过缓存避免重复计算。

* **效率**：
    * 对于本题（有向无环图），标准的回溯法可能会重复探索汇合点之后的路径。
    * 记忆化递归通过 `@lru_cache` 解决了这个问题，效率更高。当然，你也可以手动为标准回溯法添加一个记忆化缓存，那它们本质上就趋于一致了。

## 四、浅拷贝 深拷贝：
   * **浅拷贝 (Shallow Copy)**：只复制对象的第一层。如果列表中的元素是像数字、字符串这样的`不可变对象`，那浅拷贝就足够了，看起来和深拷贝没区别。但如果列表中的元素本身也是列表、字典等`可变对象`，那么浅拷贝只会复制这些内部对象的引用。
   对于浅拷贝，它会创建一个新的容器对象，然后把原始容器对象中所有元素的“引用”复制到新容器里。可以把这种“引用”想象成一个对象的内存地址或者一个指向该对象的指针。
   * **深拷贝 (Deep Copy)**：会递归地复制对象内部的所有层级。不仅第一层的列表是新的，如果里面还嵌套着列表，那么嵌套的列表也全都是新的。这需要使用 copy 模块的 deepcopy() 函数。
   * 举个例子：
   ```python
   import copy
   # 假设 path 里装的是列表，而不是整数
   original_list = [[1, 2], [3, 4]]
   # --- 浅拷贝 ---
   shallow_copied_list = list(original_list) # 或者 original_list[:]
   # --- 深拷贝 ---
   deep_copied_list = copy.deepcopy(original_list)
   
   # 现在，我们修改原始列表中的一个嵌套列表
   original_list[0][0] = 99

   # 原始列表:    [[99, 2], [3, 4]]
   # 浅拷贝的列表: [[99, 2], [3, 4]]  <-- 被一同修改了！因为它只复制了对 [1, 2] 的引用。
   # 深拷贝的列表: [[1, 2], [3, 4]]   <-- 完好无损！因为它把内部的 [1, 2] 也复制了一份。
   ```

# [解法分析] my method（经典递归DFS）

这是一个针对“通过传递路径副本的递归DFS”解法的优缺点分析。这种解法非常直观，是理解更复杂算法的一个很好的起点。

---

## 优点 (Pros)

1.  **逻辑清晰直观**
    `dfs(下一个节点, 当前路径 + [下一个节点])` 的写法完美地对应了人的自然思考过程，非常容易理解和实现。

2.  **代码简洁安全**
    由于每一层递归都使用独立的路径副本，不存在共享状态。这避免了回溯法中忘记`pop()`等操作可能导致的逻辑混乱，代码的“副作用”更少，更加安全。

---

## 缺点 (Cons)

1.  **内存效率较低**
    在递归的每一步都通过 `path + [j]` 创建一个全新的列表副本，是主要的性能瓶颈。对于层级很深或路径很长的图，这会产生大量的临时对象，导致内存开销非常大。

2.  **时间效率有待优化**
    和标准回溯法一样，这个解法没有进行记忆化处理。如果图中存在多条路径汇合到同一个节点的情况，它会对后续的公共路径进行重复的计算。

---

## 结论与展望

总而言之，这个解法是一个非常好的**“基准解法”（Baseline Solution）**。在面试或实际解题时，可以先写出这样的版本来确保正确性，然后主动向面试官指出其在内存和时间上的潜在问题，并进一步提出：
-   **优化方向1 (内存):** 使用“共享路径的回溯法”来优化内存。
-   **优化方向2 (时间):** 使用“记忆化”来优化时间效率。